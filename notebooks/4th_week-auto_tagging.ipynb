{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60457791",
   "metadata": {},
   "source": [
    "# Autotagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e73fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97164c88",
   "metadata": {},
   "source": [
    "- Download Small MTAT if you need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea84fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests[socks] in /usr/lib/python3/dist-packages (from gdown) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /home/teo/.local/lib/python3.8/site-packages (from gdown) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /home/teo/.local/lib/python3.8/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied, skipping upgrade: PySocks!=1.5.7,>=1.5.6 in /home/teo/.local/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>1.2 in /home/teo/.local/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Installing collected packages: gdown\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.4.0\n",
      "    Uninstalling gdown-4.4.0:\n",
      "      Successfully uninstalled gdown-4.4.0\n",
      "Successfully installed gdown-4.7.1\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=15e9E3oZdudErkPKwb0rCAiZXkPxdZkV6\n",
      "From (redirected): https://drive.google.com/uc?id=15e9E3oZdudErkPKwb0rCAiZXkPxdZkV6&confirm=t&uuid=82f01663-4f06-4fdd-8b20-5fbc61f7609f\n",
      "To: /home/teo/userdata/git_libraries/ant5015-2023/notebooks/mtat_8000.zip\n",
      "100%|████████████████████████████████████████| 921M/921M [01:53<00:00, 8.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gdown\n",
    "!gdown 15e9E3oZdudErkPKwb0rCAiZXkPxdZkV6\n",
    "!unzip -q mtat_8000.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de7e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTATDataset:\n",
    "  def __init__(self, dir_path, split='train', num_max_data=6000, sr=16000):\n",
    "    self.dir = Path(dir_path)\n",
    "    self.labels = pd.read_csv(self.dir / \"meta.csv\", index_col=[0])\n",
    "    self.sr = sr\n",
    "\n",
    "    if split==\"train\":\n",
    "      sub_dir_ids = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c']\n",
    "    elif split=='valid':\n",
    "      sub_dir_ids = ['d']\n",
    "    else: #test\n",
    "      sub_dir_ids = ['e', 'f', 'g']\n",
    "\n",
    "    is_in_set = [True if x[0] in sub_dir_ids else False for x in self.labels['mp3_path'].values.astype('str')]\n",
    "    self.labels = self.labels.iloc[is_in_set]\n",
    "    self.labels = self.labels[:num_max_data]\n",
    "    self.vocab = self.labels.columns.values[1:-1]\n",
    "    self.label_tensor = self.convert_label_to_tensor()\n",
    "  \n",
    "  def convert_label_to_tensor(self):\n",
    "    return torch.LongTensor(self.labels.values[:, 1:-1].astype('bool'))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "data_dir = Path('MTAT_SMALL')\n",
    "dataset= MTATDataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4074a82",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f48eb7",
   "metadata": {},
   "source": [
    "## Make Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee479ca",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757931ed",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ddf1e",
   "metadata": {},
   "source": [
    "## How CNN works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a35597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 2.,  3.,  0., -2., -2.,  1., -2.],\n",
       "           [-3., -3.,  1.,  2., -3.,  1.,  3.],\n",
       "           [-2.,  1.,  0., -3.,  0., -1., -2.],\n",
       "           [ 0., -3., -3., -2., -2., -3.,  1.],\n",
       "           [ 2.,  3.,  2.,  3.,  3., -2., -2.],\n",
       "           [ 1., -2., -1., -3., -1., -1.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  3.,  3., -3., -3.,  0.],\n",
       "           [-2.,  0.,  2.,  3.,  2., -3., -3.],\n",
       "           [-1.,  1.,  0., -2.,  3.,  1.,  3.],\n",
       "           [ 1.,  3.,  0.,  0.,  2.,  3.,  3.],\n",
       "           [-3.,  2., -3., -3.,  3., -1.,  2.],\n",
       "           [-3.,  0.,  1., -1.,  1.,  3.,  0.]]]]),\n",
       " torch.Size([1, 2, 6, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.randint(-3, 4, (2, 6,7)).float()\n",
    "dummy = dummy.unsqueeze(0)\n",
    "dummy, dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2bb41cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0329,  0.0913, -0.0989],\n",
       "          [-0.1222, -0.0248,  0.1674],\n",
       "          [ 0.0012,  0.0244, -0.2151]],\n",
       "\n",
       "         [[-0.1140,  0.2020,  0.1060],\n",
       "          [ 0.0658, -0.0340, -0.0514],\n",
       "          [-0.0025, -0.1469,  0.1981]]]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "conv_layer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=3, bias=False)\n",
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e4a71f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 1.,  1., -1.],\n",
       "          [ 0., -1., -1.],\n",
       "          [ 0.,  1.,  0.]],\n",
       "\n",
       "         [[ 1.,  0.,  0.],\n",
       "          [-1.,  0.,  1.],\n",
       "          [ 1.,  1.,  0.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.weight.shape # out_channels, in_channels, height, width\n",
    "conv_layer.weight.data = torch.randint(-1, 2, (1,2,3,3)).float()\n",
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d024aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 2.,  3.,  0., -2., -2.,  1., -2.],\n",
       "           [-3., -3.,  1.,  2., -3.,  1.,  3.],\n",
       "           [-2.,  1.,  0., -3.,  0., -1., -2.],\n",
       "           [ 0., -3., -3., -2., -2., -3.,  1.],\n",
       "           [ 2.,  3.,  2.,  3.,  3., -2., -2.],\n",
       "           [ 1., -2., -1., -3., -1., -1.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  3.,  3., -3., -3.,  0.],\n",
       "           [-2.,  0.,  2.,  3.,  2., -3., -3.],\n",
       "           [-1.,  1.,  0., -2.,  3.,  1.,  3.],\n",
       "           [ 1.,  3.,  0.,  0.,  2.,  3.,  3.],\n",
       "           [-3.,  2., -3., -3.,  3., -1.,  2.],\n",
       "           [-3.,  0.,  1., -1.,  1.,  3.,  0.]]]]),\n",
       " Parameter containing:\n",
       " tensor([[[[ 1.,  1., -1.],\n",
       "           [ 0., -1., -1.],\n",
       "           [ 0.,  1.,  0.]],\n",
       " \n",
       "          [[ 1.,  0.,  0.],\n",
       "           [-1.,  0.,  1.],\n",
       "           [ 1.,  1.,  0.]]]], requires_grad=True),\n",
       " tensor([[[[ 12.,   6.,  -1.,  -5.,  -8.],\n",
       "           [ -8.,  -4.,  12.,   5.,   2.],\n",
       "           [  5.,   8.,   0.,   7.,   7.],\n",
       "           [ -9., -11.,  -6.,  -1.,   2.]]]], grad_fn=<ThnnConv2DBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2D Conv Layer의 입력은 3차원\n",
    "\n",
    "'''\n",
    "dummy, conv_layer.weight, conv_layer(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e11f410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(dummy[:, 0:3, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa081d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c4af578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., -3.,  0., -3.,  0.,  2.,  2., -1.,  3.,  1.],\n",
       "        [-2., -1.,  3., -3.,  2.,  0.,  0.,  2.,  3., -3.],\n",
       "        [ 1., -2., -3.,  0.,  1.,  3., -3.,  1.,  3., -2.],\n",
       "        [-1., -2., -2., -3.,  0., -3., -3., -1.,  1.,  3.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ch = 4\n",
    "dummy = torch.randint(-3, 4, (num_ch, 10)).float()\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7608bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-1.,  1., -1.],\n",
       "         [ 0.,  0., -1.],\n",
       "         [ 1.,  0.,  1.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[-1.,  1., -1.],\n",
       "         [-1.,  1., -1.],\n",
       "         [ 0.,  1.,  0.],\n",
       "         [ 1., -1.,  1.]],\n",
       "\n",
       "        [[ 1., -1., -1.],\n",
       "         [ 1.,  1.,  1.],\n",
       "         [-1.,  1., -1.],\n",
       "         [ 0.,  1.,  1.]],\n",
       "\n",
       "        [[-1.,  1.,  1.],\n",
       "         [-1., -1., -1.],\n",
       "         [-1., -1., -1.],\n",
       "         [ 1.,  1.,  1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.],\n",
       "         [-1.,  0.,  0.],\n",
       "         [ 0.,  1.,  1.],\n",
       "         [ 1., -1.,  1.]],\n",
       "\n",
       "        [[ 0.,  1., -1.],\n",
       "         [ 0.,  0., -1.],\n",
       "         [ 0.,  0., -1.],\n",
       "         [-1., -1.,  1.]]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ch = 6\n",
    "conv1d = nn.Conv1d(num_ch, out_ch, kernel_size=3, bias=False)\n",
    "conv1d.weight.data = torch.randint(-1, 2, conv1d.weight.shape).float()\n",
    "conv1d.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67288206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-10.,   7.,  -7.,   4.,  -2.,   3.,  -9.,   5.],\n",
       "         [-10.,   7., -10.,   1.,   1.,  -5.,  -7.,  11.],\n",
       "         [  1.,  -7.,   4., -11.,  -3.,  -8.,   6.,   5.],\n",
       "         [ -6.,  -1.,  -8.,  -4.,  -5., -11.,  -9.,   4.],\n",
       "         [ -5., -11.,  -4.,   0.,   2.,   0.,   7.,   3.],\n",
       "         [ -2.,   7.,  -1.,  -5.,   3.,   5.,  -5.,  10.]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " torch.Size([6, 8]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv1d(dummy)\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f50d4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_layer = nn.MaxPool1d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eb822d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.,  4.],\n",
       "         [ 7.,  1.],\n",
       "         [ 4., -3.],\n",
       "         [-1., -4.],\n",
       "         [-4.,  2.],\n",
       "         [ 7.,  5.]], grad_fn=<SqueezeBackward1>),\n",
       " torch.Size([6, 2]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_pool = max_pool_layer(out)\n",
    "after_pool, after_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4901b54",
   "metadata": {},
   "source": [
    "## Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e683abc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
       "             -0.0000,     -0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000,  ...,     -0.0000,\n",
       "             -0.0000,     -0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000,  ...,     -0.0000,\n",
       "              0.0000,      0.0000],\n",
       "        ...,\n",
       "        [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
       "              0.0000,      0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000,  ...,     -0.0000,\n",
       "             -0.0000,     -0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000,  ...,     -0.0000,\n",
       "             -0.0000,     -0.0000]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
